<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"/>
  <title>Medidor √ìptico Facial ‚Äî Gu√≠a CR80 + OpenCV/MediaPipe</title>

  <!-- Tailwind -->
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- React 18 UMD + Babel -->
  <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
  <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
  <script crossorigin src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

  <!-- MediaPipe se carga on-demand dentro del script -->

  <!-- OpenCV.js (si no carga, seguimos igual con fallback) -->
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>

  <style>
    html,body{background:#eef2ff}
    video.cam{
      width:100%;
      height:auto;
      max-height:62vh;
      background:#000;
      border-radius:.75rem;
      object-fit:cover;
      transform:scaleX(-1); /* espejo c√°mara frontal */
    }
    canvas.overlay{
      position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:none;
    }
    .tag{font-variant-numeric:tabular-nums}
  </style>
</head>
<body>
<div id="root"></div>

<script type="text/babel">
const {useState,useEffect,useRef,useMemo} = React;

const CR80_W=85.60, CR80_H=53.98, CR80_AR=CR80_W/CR80_H;

/* ---------- App ---------- */
function App(){
  const [faceMeshReady,setFaceMeshReady]=useState(false);
  const [loadingModels,setLoadingModels]=useState(true);

  const [image,setImage]=useState(null);
  const [error,setError]=useState('');
  const [processing,setProcessing]=useState(false);
  const [processingStep,setProcessingStep]=useState('');
  const [annotated,setAnnotated]=useState(null);
  const [results,setResults]=useState(null);

  const videoRef=useRef(null);
  const streamRef=useRef(null);
  const overlayRef=useRef(null);
  const [cameraActive,setCameraActive]=useState(false);

  /* ---- Gu√≠a CR80 ---- */
  const [useGuide,setUseGuide]=useState(false);
  const [guideLocked,setGuideLocked]=useState(false);
  const [guidePx,setGuidePx]=useState(260);
  const [edgeMatch,setEdgeMatch]=useState(0);     // 0..1
  const [ocvMatch,setOcvMatch]=useState(0);       // 0..1
  const ocvLastRef=useRef(null);                  // { found, longSidePx, score }
  const pxPerMmFromGuide = useMemo(()=> guideLocked ? (guidePx/CR80_W) : null, [guideLocked,guidePx]);

  /* ---- MediaPipe FaceMesh (opcional) ---- */
  useEffect(()=>{
    const init=()=>{
      try{
        const fm=new window.FaceMesh({
          locateFile:f=>`https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`
        });
        fm.setOptions({maxNumFaces:1,refineLandmarks:true,minDetectionConfidence:0.5,minTrackingConfidence:0.5});
        window.__faceMesh=fm;
        setFaceMeshReady(true);
      }catch(e){ setFaceMeshReady(false); }
      finally{ setLoadingModels(false); }
    };
    if(typeof window.FaceMesh==='undefined'){
      const s=document.createElement('script');
      s.src='https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js';
      s.async=true;
      s.onload=()=>{
        const u=document.createElement('script');
        u.src='https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js';
        u.async=true; u.onload=init; u.onerror=()=>setLoadingModels(false);
        document.body.appendChild(u);
      };
      s.onerror=()=>setLoadingModels(false);
      document.body.appendChild(s);
    }else init();
  },[]);

  /* ---- C√°mara: start seguro iOS ---- */
  const startCamera=async()=>{
    setError('');
    try{
      const v=videoRef.current; if(!v) return;
      v.setAttribute('playsinline',''); v.setAttribute('autoplay',''); v.muted=true; v.playsInline=true;

      const stream=await navigator.mediaDevices.getUserMedia({
        video:{facingMode:{ideal:'user'},width:{ideal:1280},height:{ideal:720}}, audio:false
      });
      streamRef.current=stream; v.srcObject=stream;

      setCameraActive(true); // mostrar UI ya
      const tryPlay=async()=>{ try{await v.play();}catch(e){ setTimeout(()=>v.play().catch(()=>{}),120);} };
      tryPlay();
    }catch(err){
      setError('No se pudo acceder a la c√°mara: '+err.message);
      setCameraActive(false);
    }
  };
  const stopCamera=()=>{
    try{
      const v=videoRef.current; if(v){v.pause(); v.srcObject=null;}
      if(streamRef.current){streamRef.current.getTracks().forEach(t=>t.stop()); streamRef.current=null;}
    }finally{
      setCameraActive(false); setUseGuide(false); setGuideLocked(false);
      setEdgeMatch(0); setOcvMatch(0); ocvLastRef.current=null;
    }
  };

  /* ---------- OpenCV helper en ROI ---------- */
  function openCvDetectCardInROI(imageData, gw, gh){
    // Devuelve {found, longSidePx, score} o null si cv no est√°
    const cv=window.cv;
    if(!cv || !cv.Mat) return null;
    try{
      const src = cv.matFromImageData(imageData);          // RGBA
      const gray = new cv.Mat(), blur = new cv.Mat(), edges = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
      cv.GaussianBlur(gray, blur, new cv.Size(5,5), 0);

      // Umbrales por luminancia media
      let sum=0; const d=blur.data; for(let i=0;i<d.length;i++) sum+=d[i];
      const mean=sum/d.length; const low=Math.max(0,0.66*mean), high=Math.min(255,1.33*mean);
      cv.Canny(blur, edges, low, high);

      const contours=new cv.MatVector(); const hier=new cv.Mat();
      cv.findContours(edges, contours, hier, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

      let best=null, bestScore=0;
      for(let i=0;i<contours.size();i++){
        const cnt=contours.get(i);
        const area=cv.contourArea(cnt);
        if(area < (gw*gh)*0.06){ cnt.delete(); continue; } // ignora chico
        const peri=cv.arcLength(cnt,true);
        const approx=new cv.Mat(); cv.approxPolyDP(cnt,approx,0.02*peri,true);
        if(approx.rows===4){
          const rect=cv.minAreaRect(cnt);
          const W=rect.size.width, H=rect.size.height;
          const long=Math.max(W,H), short=Math.min(W,H);
          const ar=long/short;
          const aspectScore = Math.max(0, 1 - Math.min(Math.abs(ar- (CR80_AR))/0.3, 1)); // tolerancia ~¬±0.3
          // continuidad de borde (aprox con relaci√≥n √°rea)
          const continuity = Math.max(0, Math.min(1, (area/(gw*gh))*2.2));
          const score = aspectScore*0.7 + continuity*0.3;
          if(score>bestScore){ bestScore=score; best={found:true,longSidePx:long,score}; }
        }
        approx.delete(); cnt.delete();
      }
      gray.delete(); blur.delete(); edges.delete(); contours.delete(); hier.delete(); src.delete();
      return best || {found:false,longSidePx:0,score:0};
    }catch(e){
      console.log('OpenCV ROI error',e);
      return null;
    }
  }

  /* ---- Loop overlay: bordes + OpenCV en ROI ---- */
  useEffect(()=>{
    if(!cameraActive || !useGuide) return;
    let raf=0, frame=0;
    const v=videoRef.current, c=overlayRef.current;
    const ctx=c.getContext('2d',{willReadFrequently:true});

    const loop=()=>{
      if(!v.videoWidth){ raf=requestAnimationFrame(loop); return; }
      c.width=v.videoWidth; c.height=v.videoHeight;

      // Pintar frame espejo para que el usuario se vea con gu√≠a encima
      ctx.save(); ctx.scale(-1,1); ctx.drawImage(v,-c.width,0,c.width,c.height); ctx.restore();

      const gw=guidePx, gh=Math.round(guidePx/CR80_AR);
      const gx=Math.round((c.width-gw)/2), gy=Math.round((c.height-gh)/2);

      // 1) Bordes per√≠metro (r√°pido)
      const img=ctx.getImageData(gx,gy,gw,gh);
      const thick=3; let edge=0, total=0;
      const isEdge=(r,g,b)=>{ const lum=0.299*r+0.587*g+0.114*b; return (lum<80 || lum>200); };
      for(let y=0;y<gh;y++){
        for(let x=0;x<gw;x++){
          const bt=(y<thick)||(y>=gh-thick)||(x<thick)||(x>=gw-thick);
          if(!bt) continue;
          const i=(y*gw+x)*4; if(isEdge(img.data[i],img.data[i+1],img.data[i+2])) edge++; total++;
        }
      }
      const edgeScore = total? edge/total : 0;
      setEdgeMatch(edgeScore);

      // 2) OpenCV (cada 3 frames para rendimiento)
      if(frame%3===0){
        const ocv = openCvDetectCardInROI(img, gw, gh);
        if(ocv){
          ocvLastRef.current = ocv;
          setOcvMatch( ocv.found ? ocv.score : 0 );
        }
      }
      frame++;

      // Dibujar overlay gris + ROI
      ctx.fillStyle='rgba(0,0,0,.35)'; ctx.fillRect(0,0,c.width,c.height);
      ctx.clearRect(gx,gy,gw,gh);
      const combined = Math.max(edgeScore, ocvMatch);
      ctx.strokeStyle = combined>=0.7 ? '#22c55e' : '#a78bfa';
      ctx.lineWidth=4; ctx.strokeRect(gx,gy,gw,gh);

      ctx.font='bold 16px system-ui, -apple-system';
      ctx.fillStyle='#fff';
      const pct1=Math.round(edgeScore*100), pct2=Math.round((ocvMatch||0)*100);
      ctx.fillText(`Gu√≠a CR80 ‚Ä¢ Match ${pct1}%, OpenCV ${pct2}%`, gx+12, Math.max(24, gy-10));

      raf=requestAnimationFrame(loop);
    };
    raf=requestAnimationFrame(loop);
    return()=> cancelAnimationFrame(raf);
  },[cameraActive,useGuide,guidePx,ocvMatch]);

  /* ---- Capturar frame actual ---- */
  const capturePhoto=()=>{
    const v=videoRef.current; if(!v || !v.videoWidth){ setError('La c√°mara a√∫n no est√° lista.'); return; }
    const c=document.createElement('canvas'); c.width=v.videoWidth; c.height=v.videoHeight;
    const x=c.getContext('2d'); x.drawImage(v,0,0,c.width,c.height); // sin espejo
    const url=c.toDataURL('image/jpeg',0.92);
    setImage(url); setAnnotated(null); setResults(null); setError('');
  };

  /* ---- Subir ---- */
  const onUpload=e=>{
    const f=e.target.files?.[0]; if(!f) return;
    const rd=new FileReader();
    rd.onload=ev=>{ setImage(ev.target.result); setAnnotated(null); setResults(null); setError(''); };
    rd.readAsDataURL(f);
  };

  /* ---- Procesar (simplificado + escalas) ---- */
  const process=async()=>{
    if(!image){ setError('No hay imagen para procesar.'); return; }
    setProcessing(true); setProcessingStep('Preparando‚Ä¶'); setError('');
    try{
      const img=await new Promise((res,rej)=>{ const m=new Image(); m.src=image; m.onload=()=>res(m); m.onerror=rej; });

      // 1) Escala
      let pxPerMm=null;
      if(pxPerMmFromGuide){ pxPerMm = pxPerMmFromGuide; }
      else if(ocvLastRef.current?.found && ocvLastRef.current.longSidePx){
        pxPerMm = ocvLastRef.current.longSidePx / CR80_W; // detectado en ROI
      }else{
        // fallback suave
        const approxWidthPx = Math.min(img.width,img.height)*0.22;
        pxPerMm = approxWidthPx / CR80_W;
      }

      // 2) Landmarks (MediaPipe si est√°, si no estimaci√≥n)
      const getLandmarks=()=> new Promise((resolve)=>{
        if(window.__faceMesh){
          const c=document.createElement('canvas'); c.width=img.width; c.height=img.height;
          c.getContext('2d').drawImage(img,0,0);
          window.__faceMesh.onResults(r=>{
            if(r.multiFaceLandmarks && r.multiFaceLandmarks[0]){
              const L=r.multiFaceLandmarks[0];
              const iris=a=>({x:a.reduce((s,l)=>s+l.x*img.width,0)/a.length,y:a.reduce((s,l)=>s+l.y*img.height,0)/a.length});
              resolve({ rightPupil:iris(L.slice(468,472)), leftPupil:iris(L.slice(473,477)), method:'MediaPipe', confidence:0.95 });
            }else{
              const cx=img.width/2, cy=img.height*0.45, d=img.width*0.15;
              resolve({ rightPupil:{x:cx+d/2,y:cy}, leftPupil:{x:cx-d/2,y:cy}, method:'Estimaci√≥n', confidence:0.65 });
            }
          });
          window.__faceMesh.send({image:c});
        }else{
          const cx=img.width/2, cy=img.height*0.45, d=img.width*0.15;
          resolve({ rightPupil:{x:cx+d/2,y:cy}, leftPupil:{x:cx-d/2,y:cy}, method:'Estimaci√≥n', confidence:0.65 });
        }
      });

      setProcessingStep('Detectando pupilas‚Ä¶');
      const lm = await getLandmarks();

      // 3) IPD
      const dx=lm.rightPupil.x-lm.leftPupil.x, dy=lm.rightPupil.y-lm.leftPupil.y;
      const ipd_mm = Math.round((Math.hypot(dx,dy)/pxPerMm)*10)/10;

      // 4) Imagen anotada
      const out=document.createElement('canvas'); out.width=img.width; out.height=img.height;
      const a=out.getContext('2d'); a.drawImage(img,0,0);
      a.fillStyle='#f00';
      a.beginPath(); a.arc(lm.leftPupil.x,lm.leftPupil.y,10,0,Math.PI*2); a.fill();
      a.beginPath(); a.arc(lm.rightPupil.x,lm.rightPupil.y,10,0,Math.PI*2); a.fill();
      a.strokeStyle='#f00'; a.lineWidth=3; a.beginPath();
      a.moveTo(lm.leftPupil.x,lm.leftPupil.y); a.lineTo(lm.rightPupil.x,lm.rightPupil.y); a.stroke();
      a.font='bold 20px system-ui, -apple-system'; a.fillStyle='#fff'; a.strokeStyle='#000'; a.lineWidth=4;
      const mx=(lm.leftPupil.x+lm.rightPupil.x)/2, my=(lm.leftPupil.y+lm.rightPupil.y)/2-20;
      a.strokeText(`IPD: ${ipd_mm} mm`, mx-60,my); a.fillText(`IPD: ${ipd_mm} mm`, mx-60,my);
      const annotatedUrl=out.toDataURL('image/png');

      setResults({
        detectionMethod: lm.method,
        calibration: { px_per_mm:pxPerMm, from_guide: !!pxPerMmFromGuide, from_ocv: (!pxPerMmFromGuide && !!ocvLastRef.current?.found) },
        measurements: { DI_mm: ipd_mm }
      });
      setAnnotated(annotatedUrl);
      setProcessingStep('¬°Listo!');
    }catch(e){
      console.error(e);
      setError('No se pudo procesar la imagen: '+(e.message||e));
    }finally{
      setTimeout(()=>{ setProcessing(false); setProcessingStep(''); }, 400);
    }
  };

  /* ---------- UI ---------- */
  return (
    <div className="min-h-screen p-4">
      <div className="max-w-3xl mx-auto space-y-4">
        <div className="bg-white rounded-2xl shadow p-5 border-t-4 border-indigo-500">
          <div className="flex items-center justify-between">
            <div>
              <h1 className="text-3xl font-bold">Medidor √ìptico Facial</h1>
              <p className="text-slate-600">Gu√≠a CR80 + Detecci√≥n (OpenCV/MediaPipe)</p>
            </div>
            <div className={`px-3 py-1 rounded-lg text-sm ${faceMeshReady?'bg-emerald-50 text-emerald-700':'bg-indigo-50 text-indigo-700'}`}>
              {faceMeshReady?'‚úÖ MediaPipe':'‚¨áÔ∏è Cargando‚Ä¶'}
            </div>
          </div>
        </div>

        <div className="bg-white rounded-2xl shadow p-5">
          <h2 className="text-xl font-semibold mb-3">Captura de Imagen</h2>
          <div className="grid grid-cols-2 gap-3">
            <label className="inline-flex items-center justify-center gap-2 bg-indigo-600 hover:bg-indigo-700 text-white font-semibold py-3 rounded-xl cursor-pointer">
              üñºÔ∏è <span>Subir Foto</span>
              <input type="file" className="hidden" accept="image/*" onChange={onUpload}/>
            </label>
            {!cameraActive ? (
              <button onClick={startCamera} className="inline-flex items-center justify-center gap-2 bg-violet-600 hover:bg-violet-700 text-white font-semibold py-3 rounded-xl">üì∑ C√°mara</button>
            ) : (
              <button onClick={stopCamera} className="inline-flex items-center justify-center gap-2 bg-rose-600 hover:bg-rose-700 text-white font-semibold py-3 rounded-xl">üõë Cerrar C√°mara</button>
            )}
          </div>

          {cameraActive && (
            <div className="mt-4 relative">
              <video ref={videoRef} className="cam" autoplay playsinline muted></video>
              {useGuide && <canvas ref={overlayRef} className="overlay"></canvas>}

              <div className="mt-3 flex flex-wrap items-center gap-3">
                <label className="inline-flex items-center gap-2">
                  <input type="checkbox" className="scale-110" checked={useGuide}
                         onChange={e=>{ setUseGuide(e.target.checked); setGuideLocked(false); }}/>
                  <span>Usar Gu√≠a CR80</span>
                </label>

                {useGuide && (
                  <>
                    <div className="flex-1 min-w-[220px]">
                      <input type="range" min="140" max="420" value={guidePx}
                             onChange={e=> setGuidePx(parseInt(e.target.value))} className="w-full"/>
                      <div className="text-xs text-slate-600">Ancho gu√≠a: <span className="tag">{guidePx}px</span> (alto {Math.round(guidePx/CR80_AR)}px)</div>
                    </div>
                    <div className="px-2 py-1 rounded-md text-sm bg-slate-100">
                      <div>Match (Bordes): <b className="tag">{Math.round(edgeMatch*100)}%</b></div>
                      <div>Match (OpenCV): <b className="tag">{Math.round(ocvMatch*100)}%</b></div>
                    </div>
                    {!guideLocked ? (
                      <button onClick={()=> setGuideLocked(true)}
                              disabled={Math.max(edgeMatch,ocvMatch) < 0.7}
                              className={`px-3 py-2 rounded-lg text-white ${Math.max(edgeMatch,ocvMatch)<0.7?'bg-slate-400 cursor-not-allowed':'bg-emerald-600 hover:bg-emerald-700'}`}>
                        Bloquear gu√≠a
                      </button>
                    ) : (
                      <div className="text-emerald-700 text-sm">Gu√≠a bloqueada ‚úì (escala fija)</div>
                    )}
                  </>
                )}

                <button onClick={capturePhoto} className="ml-auto inline-flex items-center justify-center gap-2 bg-blue-600 hover:bg-blue-700 text-white font-semibold px-4 py-2 rounded-xl">
                  üì∏ Capturar
                </button>
              </div>
            </div>
          )}
        </div>

        {image && (
          <div className="bg-white rounded-2xl shadow p-5">
            <h3 className="font-semibold mb-3">Imagen Actual</h3>
            <img src={image} alt="captura" className="w-full rounded-lg shadow"/>
            <button onClick={process} disabled={processing}
                    className="mt-4 inline-flex items-center justify-center gap-2 bg-emerald-600 hover:bg-emerald-700 disabled:bg-slate-400 text-white font-semibold px-4 py-2 rounded-xl">
              üßÆ {processing?'Procesando‚Ä¶':'Procesar'}
            </button>
            {processing && <div className="text-sm text-slate-600 mt-2">{processingStep}</div>}
          </div>
        )}

        {results && (
          <div className="bg-white rounded-2xl shadow p-5 space-y-3">
            <div className="flex items-center justify-between">
              <h3 className="font-semibold">Resultado</h3>
              <span className="text-xs px-2 py-1 rounded bg-slate-100">{results.detectionMethod}</span>
            </div>
            <div className="grid grid-cols-2 gap-3">
              <div className="p-3 rounded bg-indigo-50">
                <div className="text-xs text-slate-600">IPD</div>
                <div className="text-2xl font-bold">{results.measurements.DI_mm} mm</div>
              </div>
              <div className="p-3 rounded bg-violet-50">
                <div className="text-xs text-slate-600">Escala (px/mm)</div>
                <div className="text-xl font-semibold tag">{results.calibration.px_per_mm.toFixed(3)}</div>
                <div className="text-xs text-slate-500">
                  {results.calibration.from_guide ? 'De gu√≠a CR80' : results.calibration.from_ocv ? 'OpenCV en ROI' : 'Estimaci√≥n'}
                </div>
              </div>
            </div>
            {annotated && (
              <div className="mt-2">
                <h4 className="font-semibold mb-2">Imagen Anotada</h4>
                <img src={annotated} className="w-full rounded-lg shadow" alt="anotada"/>
                <a download={`annotated-${Date.now()}.png`} href={annotated}
                   className="inline-block mt-3 px-3 py-2 rounded bg-blue-600 text-white">Descargar PNG</a>
              </div>
            )}
          </div>
        )}

        {error && (
          <div className="bg-red-50 text-red-800 border border-red-200 rounded-xl p-4">
            <div className="font-semibold mb-1">Error</div>
            <div className="text-sm">{error}</div>
          </div>
        )}

        <div className="bg-white rounded-2xl shadow p-5">
          <h3 className="font-semibold mb-2">C√≥mo usar la Gu√≠a CR80</h3>
          <ol className="list-decimal ml-5 space-y-1 text-sm text-slate-700">
            <li>Enciende la c√°mara y activa ‚ÄúUsar Gu√≠a CR80‚Äù.</li>
            <li>Ajusta el tama√±o y coloca una tarjeta real dentro del rect√°ngulo.</li>
            <li>Cuando ‚ÄúMatch‚Äù (Bordes u OpenCV) ‚â• 70%, presiona <b>Bloquear gu√≠a</b> y luego <b>Capturar</b>.</li>
            <li>Al procesar, si no bloqueaste, el sistema intentar√° usar la detecci√≥n OpenCV de la ROI.</li>
          </ol>
          <p className="text-xs text-slate-500 mt-2">La gu√≠a fija la escala: px/mm = ancho_gu√≠a_px / 85.60.</p>
        </div>

        <div className="text-center text-xs text-slate-500 py-4">¬© 2025 ‚Äî CR80 Guide + OpenCV + MediaPipe</div>
      </div>
    </div>
  );
}

const root = ReactDOM.createRoot(document.getElementById('root'));
root.render(<App/>);
</script>
</body>
</html>