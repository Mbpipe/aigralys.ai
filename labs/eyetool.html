<!doctype html>
<html lang="es">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Medidor Óptico Facial</title>

<!-- Tailwind -->
<script src="https://cdn.tailwindcss.com"></script>

<!-- React 18 UMD + Babel -->
<script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
<script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
<script crossorigin src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

<!-- OpenCV (opcional para fallback de tarjeta) -->
<script src="https://docs.opencv.org/4.x/opencv.js"></script>

<style>
  html,body{background:#eef2ff}
  .hidden-canvas{display:none}
  /* Máscara con ventana CR80 */
  .mask{position:absolute;inset:0;pointer-events:none;--w:60vmin;--h:calc(var(--w)/1.586);
    background:radial-gradient(ellipse var(--w) var(--h) at 50% 50%, transparent 99%, rgba(0,0,0,.55) 100%)}
  .guide-rect{position:absolute;left:50%;top:50%;transform:translate(-50%,-50%);
    border:3px dashed #10b981;border-radius:8px;pointer-events:none}
  /* Mantener alto siempre para iOS */
  .video-shell{position:relative; background:#000; border-radius: .75rem; overflow:hidden;
    aspect-ratio:16/9;}
  video{display:block; width:100%; height:auto; background:#000}
</style>
</head>
<body>
<div id="root"></div>

<script type="text/babel" data-presets="env,react">
const {useState,useRef,useEffect} = React;

const Icon = ({children}) => <span className="inline-flex w-5 h-5 items-center justify-center">{children}</span>;
const I={eye:"👁️", up:"📤", cam:"📷", rule:"📏", ok:"✅", warn:"⚠️", dl:"⬇️", info:"ℹ️", spin:"⏳", bolt:"⚡"};

const CR80W=85.60, CR80H=53.98, RATIO=CR80W/CR80H;

// ------- OpenCV tarjeta (fallback) --------
const detectCardWithOpenCV = (canvas)=>{
  try{
    if(!window.cv || !cv.Mat) return {found:false};
    const src=cv.imread(canvas), gray=new cv.Mat(), blur=new cv.Mat(), edges=new cv.Mat();
    cv.cvtColor(src,gray,cv.COLOR_RGBA2GRAY,0); cv.GaussianBlur(gray,blur,new cv.Size(5,5),0);
    let sum=0; for(const v of blur.data) sum+=v; const mean=sum/blur.data.length;
    cv.Canny(blur,edges,Math.max(0,.66*mean),Math.min(255,1.33*mean));
    const kernel=cv.getStructuringElement(cv.MORPH_RECT,new cv.Size(3,3)); cv.dilate(edges,edges,kernel);
    const contours=new cv.MatVector(), hier=new cv.Mat();
    cv.findContours(edges,contours,hier,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE);
    let best=null, bestScore=0;
    for(let i=0;i<contours.size();i++){
      const cnt=contours.get(i), area=cv.contourArea(cnt);
      if(area < (src.rows*src.cols)*0.002){ cnt.delete(); continue; }
      const peri=cv.arcLength(cnt,true), approx=new cv.Mat();
      cv.approxPolyDP(cnt,approx,0.02*peri,true);
      if(approx.rows===4){
        const rect=cv.minAreaRect(cnt); const w=rect.size.width, h=rect.size.height;
        const long=Math.max(w,h), short=Math.min(w,h), ar=long/short;
        if(Math.abs(ar-RATIO)<=RATIO*0.15){
          const score=(area/(src.rows*src.cols))*0.8 + (1-Math.min(Math.abs(rect.angle)/90,1))*0.2;
          if(score>bestScore){
            const box=new cv.Mat(); cv.boxPoints(rect,box); const f=box.data32F;
            best={found:true,corners:[{x:f[0],y:f[1]},{x:f[2],y:f[3]},{x:f[4],y:f[5]},{x:f[6],y:f[7]}],
                  longSidePx:long, shortSidePx:short, angle:rect.angle, confidence:Math.min(.95,score*2)};
            bestScore=score; box.delete();
          }
        }
      }
      approx.delete(); cnt.delete();
    }
    gray.delete(); blur.delete(); edges.delete(); contours.delete(); hier.delete(); src.delete();
    return best || {found:false};
  }catch(e){ console.log("OpenCV error:",e); return {found:false}; }
};

// ------- MediaPipe FaceMesh loader -------
const useFaceMesh=()=>{
  const faceMeshRef=useRef(null);
  const [ready,setReady]=useState(false);
  const [loading,setLoading]=useState(true);
  useEffect(()=>{
    const init=()=>{
      try{
        const fm=new window.FaceMesh({locateFile:(f)=>`https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`});
        fm.setOptions({maxNumFaces:1,refineLandmarks:true,minDetectionConfidence:.5,minTrackingConfidence:.5});
        faceMeshRef.current=fm; setReady(true); setLoading(false);
      }catch(e){ console.error(e); setReady(false); setLoading(false); }
    };
    if(typeof window.FaceMesh==="undefined"){
      const s=document.createElement("script");
      s.src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"; s.async=true;
      s.onload=()=>{
        const s2=document.createElement("script");
        s2.src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"; s2.async=true;
        s2.onload=init; s2.onerror=()=>{setReady(false);setLoading(false)};
        document.body.appendChild(s2);
      };
      s.onerror=()=>{setReady(false);setLoading(false)}; document.body.appendChild(s);
    } else init();
  },[]);
  return {faceMeshRef,ready,loading};
};

const detectFaceWithMediaPipe=(fmRef,img)=>new Promise((resolve,reject)=>{
  const c=document.createElement("canvas"); c.width=img.width; c.height=img.height;
  c.getContext("2d").drawImage(img,0,0);
  fmRef.current.onResults((r)=>{
    if(r.multiFaceLandmarks && r.multiFaceLandmarks[0]){
      const L=r.multiFaceLandmarks[0];
      const ri=L.slice(468,472), li=L.slice(473,477);
      const rp={x:ri.reduce((s,k)=>s+k.x*img.width,0)/4,y:ri.reduce((s,k)=>s+k.y*img.height,0)/4};
      const lp={x:li.reduce((s,k)=>s+k.x*img.width,0)/4,y:li.reduce((s,k)=>s+k.y*img.height,0)/4};
      resolve({rightPupil:rp,leftPupil:lp,faceCenter:{x:(rp.x+lp.x)/2,y:(rp.y+lp.y)/2},
               noseTip:{x:L[1].x*img.width,y:L[1].y*img.height},
               chinBottom:{x:L[152].x*img.width,y:L[152].y*img.height},
               confidence:.95, method:"MediaPipe"});
    } else reject(new Error("No se detectó rostro"));
  });
  fmRef.current.send({image:c});
});

const detectFaceFallback=(w,h)=>{
  const cx=w/2, cy=h*.45, ipd=w*.15;
  return {rightPupil:{x:cx+ipd/2,y:cy}, leftPupil:{x:cx-ipd/2,y:cy},
          noseTip:{x:cx,y:cy+h*.08}, chinBottom:{x:cx,y:cy+h*.25},
          faceCenter:{x:cx,y:cy}, confidence:.7, method:"Estimación"};
};

// ------- Medición “match” de guía -------
const measureGuideMatch=(ctx,rect)=>{
  const {x,y,w,h}=rect; const L=Math.round(x-w/2), R=Math.round(x+w/2), T=Math.round(y-h/2), B=Math.round(y+h/2);
  const im=ctx.getImageData(0,0,ctx.canvas.width,ctx.canvas.height); const d=im.data, W=im.width;
  const step=Math.max(4,Math.round(w/100)); let score=0,cnt=0;
  const sample=(x1,y1,x2,y2)=>{
    const dx=x2-x1, dy=y2-y1, len=Math.hypot(dx,dy), n=Math.max(2,Math.floor(len/step));
    for(let i=0;i<=n;i++){
      const t=i/n, sx=Math.round(x1+dx*t), sy=Math.round(y1+dy*t); if(sx<2||sy<2||sx>=im.width-2||sy>=im.height-2) continue;
      const idx=(sy*W+sx)*4;
      const c =(d[idx]+d[idx+1]+d[idx+2])/3;
      const c1=(d[idx+4]+d[idx+5]+d[idx+6])/3, c2=(d[idx-4]+d[idx-3]+d[idx-2])/3;
      const local=Math.abs(c1-c2); score+=Math.min(1,local/60); cnt++;
    }
  };
  sample(L,T,R,T); sample(R,T,R,B); sample(R,B,L,B); sample(L,B,L,T);
  return cnt? (score/cnt):0;
};

function App(){
  const {faceMeshRef,ready:faceReady,loading:faceLoading}=useFaceMesh();

  const [image,setImage]=useState(null);
  const [results,setResults]=useState(null);
  const [annotated,setAnnotated]=useState(null);
  const [error,setError]=useState(null);
  const [processing,setProcessing]=useState(false);
  const [step,setStep]=useState("");

  const videoRef=useRef(null);
  const canvasRef=useRef(null);
  const fileRef=useRef(null);

  const [cameraActive,setCameraActive]=useState(false);
  const [videoReady,setVideoReady]=useState(false);

  // Guía CR80
  const [useGuide,setUseGuide]=useState(true);
  const [guideScale,setGuideScale]=useState(55);
  const [guideMatch,setGuideMatch]=useState(0);
  const [guideLock,setGuideLock]=useState(false);

  // OpenCV listo?
  const [cvReady,setCvReady]=useState(false);
  useEffect(()=>{
    const ok=()=> (window.cv && typeof cv.Mat!=="undefined");
    if(ok()){ setCvReady(true); return; }
    if(window.cv && cv.onRuntimeInitialized){ cv.onRuntimeInitialized=()=>setCvReady(true); }
  },[]);

  const startCamera=async()=>{
    try{
      const stream=await navigator.mediaDevices.getUserMedia({video:{facingMode:"user",width:1280,height:720},audio:false});
      const v=videoRef.current;
      if(v){
        // Atributos que iOS necesita explícitos
        v.setAttribute('playsinline','true');
        v.setAttribute('autoplay','true');
        v.muted=true; v.removeAttribute('controls');
        v.srcObject=stream;
        v.onloadedmetadata=async ()=>{
          try{ await v.play(); }catch(_){}
          setVideoReady(true);
        };
        setCameraActive(true);
        setImage(null); setResults(null); setAnnotated(null); setError(null);
      }
    }catch(e){ setError("No se pudo acceder a la cámara: "+e.message); }
  };

  const stopCamera=()=>{
    const v=videoRef.current;
    if(v && v.srcObject){ v.srcObject.getTracks().forEach(t=>t.stop()); v.srcObject=null; }
    setCameraActive(false); setVideoReady(false);
  };

  const capturePhoto=()=>{
    const v=videoRef.current; if(!v) return;
    const c=document.createElement('canvas'); c.width=v.videoWidth; c.height=v.videoHeight;
    c.getContext('2d').drawImage(v,0,0); const data=c.toDataURL('image/jpeg');
    setImage(data); stopCamera();
  };

  const onUpload=(e)=>{
    const f=e.target.files?.[0]; if(!f) return;
    const r=new FileReader(); r.onload=(ev)=>{ setImage(ev.target.result); setResults(null); setAnnotated(null); setError(null); };
    r.readAsDataURL(f);
  };

  // Guía: rect en coords del video
  const getGuideRect=()=>{
    const v=videoRef.current; if(!v) return null;
    const vw=v.videoWidth||1280, vh=v.videoHeight||720;
    let gw=Math.max(120, Math.min(vw*.9, vw*(guideScale/100))), gh=gw/RATIO;
    if(gh>vh*.8){ gh=vh*.8; gw=gh*RATIO; }
    return {x:vw/2,y:vh/2,w:gw,h:gh};
  };

  // loop para calcular match mientras la cámara corre
  useEffect(()=>{
    if(!cameraActive || !useGuide) return;
    let id;
    const loop=()=>{
      const v=videoRef.current, c=canvasRef.current; if(!v||!c){ id=requestAnimationFrame(loop); return; }
      c.width=v.videoWidth; c.height=v.videoHeight;
      const ctx=c.getContext('2d'); ctx.drawImage(v,0,0,c.width,c.height);
      const r=getGuideRect(); if(r){ setGuideMatch(measureGuideMatch(ctx,r)); }
      id=requestAnimationFrame(loop);
    };
    id=requestAnimationFrame(loop);
    return ()=>cancelAnimationFrame(id);
  },[cameraActive,useGuide,guideScale]);

  const analyze=async()=>{
    try{
      if(!image) return;
      setProcessing(true); setError(null); setStep("Cargando imagen…");
      // Imagen
      const img=new Image(); img.src=image;
      await new Promise((res,rej)=>{img.onload=res; img.onerror=rej;});
      const C=canvasRef.current; C.width=img.width; C.height=img.height;
      const ctx=C.getContext('2d'); ctx.drawImage(img,0,0);

      // Cara
      setStep("Detectando rostro…");
      let lm;
      if(faceReady && window.FaceMesh){ try{ lm=await detectFaceWithMediaPipe({current:window.faceMesh||faceMeshRef.current},img); }catch{ lm=detectFaceFallback(C.width,C.height);} }
      else { lm=detectFaceFallback(C.width,C.height); }

      // Tarjeta: guía bloqueada -> escala directa, sino OpenCV
      setStep("Escalando por CR80…");
      let pxPerMm=null, card=null, usedGuide=false;
      if(guideLock && !cameraActive){ // guía se bloquea antes de capturar; al capturar el frame coincide
        // como la foto viene de la misma cámara, las dimensiones coinciden con la guía usada al capturar
        // aproximamos la guía al centro de la imagen
        const gw = img.width*(guideScale/100), gh=gw/RATIO;
        pxPerMm = (gw)/CR80W; usedGuide=true;
        card={found:true, corners:[
          {x:img.width/2-gw/2,y:img.height/2-gh/2},
          {x:img.width/2+gw/2,y:img.height/2-gh/2},
          {x:img.width/2+gw/2,y:img.height/2+gh/2},
          {x:img.width/2-gw/2,y:img.height/2+gh/2}
        ]};
      }
      if(!pxPerMm){
        if(!cvReady) throw new Error("OpenCV aún no está listo. Espera unos segundos o usa la guía bloqueada.");
        setStep("Buscando tarjeta con OpenCV…");
        const res=detectCardWithOpenCV(C);
        if(!res.found) throw new Error("No se detectó la tarjeta. Usa la Guía CR80 o mejora la iluminación.");
        pxPerMm = (res.longSidePx)/CR80W; card=res;
      }

      // Medidas
      setStep("Calculando IPD…");
      const diPx=Math.hypot(lm.rightPupil.x-lm.leftPupil.x,lm.rightPupil.y-lm.leftPupil.y);
      const DI_mm = diPx/pxPerMm;
      const meas={DI_mm:Math.round(DI_mm*10)/10, A_right_mm:null,A_left_mm:null,B_right_mm:null,B_left_mm:null, extras:{}};

      // Anotada
      const A=document.createElement('canvas'); A.width=img.width; A.height=img.height;
      const a=A.getContext('2d'); a.drawImage(img,0,0);
      if(card?.corners){ a.strokeStyle="#10b981"; a.lineWidth=4; a.beginPath();
        a.moveTo(card.corners[0].x,card.corners[0].y); for(let i=1;i<card.corners.length;i++) a.lineTo(card.corners[i].x,card.corners[i].y);
        a.closePath(); a.stroke(); }
      a.fillStyle="#ef4444"; a.beginPath(); a.arc(lm.rightPupil.x,lm.rightPupil.y,10,0,Math.PI*2); a.fill();
      a.beginPath(); a.arc(lm.leftPupil.x,lm.leftPupil.y,10,0,Math.PI*2); a.fill();
      a.strokeStyle="#ef4444"; a.lineWidth=3; a.beginPath(); a.moveTo(lm.leftPupil.x,lm.leftPupil.y); a.lineTo(lm.rightPupil.x,lm.rightPupil.y); a.stroke();
      const midx=(lm.leftPupil.x+lm.rightPupil.x)/2, midy=(lm.leftPupil.y+lm.rightPupil.y)/2-18;
      a.fillStyle="#fff"; a.strokeStyle="#000"; a.lineWidth=4; a.font="bold 18px Arial";
      a.strokeText(`IPD: ${meas.DI_mm} mm`,midx-60,midy); a.fillText(`IPD: ${meas.DI_mm} mm`,midx-60,midy);
      setAnnotated(A.toDataURL());

      setResults({
        measurements:meas,
        calibration:{px_per_mm:pxPerMm, method: usedGuide?"Guía CR80":"OpenCV"},
        quality:{confidence_DI:lm.confidence, flags:[], notes: usedGuide?"Escala fijada por guía.":""},
        detectionMethod: lm.method
      });
      setStep("Listo");
    }catch(e){ setError(e.message||String(e)); } finally { setProcessing(false); setStep(""); }
  };

  const downloadPNG=()=>{ if(!annotated) return; const a=document.createElement("a"); a.href=annotated; a.download=`annotated-${Date.now()}.png`; a.click(); };
  const downloadJSON=()=>{ if(!results) return; const b=new Blob([JSON.stringify(results,null,2)],{type:"application/json"}); const url=URL.createObjectURL(b); const a=document.createElement("a"); a.href=url; a.download=`results-${Date.now()}.json`; a.click(); URL.revokeObjectURL(url); };

  // Dimensiones visuales de guía (en píxeles del elemento, no del stream)
  const liveGuideStyle = ()=>{
    const el = document.querySelector('.video-shell');
    if(!el) return {display:'none'};
    const w = Math.max(120, (guideScale/100)*(el.clientWidth||600));
    const h = w/RATIO;
    return {width:`${w}px`, height:`${h}px`, borderColor: guideMatch>=.7 ? '#16a34a' : '#10b981'};
  };

  return (
    <div className="min-h-screen p-4">
      <div className="max-w-3xl mx-auto">
        <div className="bg-white rounded-2xl shadow-xl p-6 mb-6 border-t-4 border-indigo-600">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-3">
              <div className="bg-indigo-100 p-3 rounded-xl"><Icon>{I.eye}</Icon></div>
              <div>
                <h1 className="text-2xl sm:text-3xl font-bold text-gray-800">Medidor Óptico Facial</h1>
                <p className="text-gray-600 mt-1">Guía CR80 + Detección (OpenCV/MediaPipe)</p>
              </div>
            </div>
            <div>
              {faceLoading ? <span className="text-sm text-yellow-700 bg-yellow-50 px-3 py-1 rounded-lg inline-flex items-center gap-2"><Icon>{I.spin}</Icon>MediaPipe</span>
               : faceReady ? <span className="text-sm text-green-700 bg-green-50 px-3 py-1 rounded-lg inline-flex items-center gap-2"><Icon>{I.ok}</Icon>MediaPipe</span>
               : <span className="text-sm text-blue-700 bg-blue-50 px-3 py-1 rounded-lg inline-flex items-center gap-2"><Icon>{I.bolt}</Icon>Estimación</span>}
            </div>
          </div>
        </div>

        <div className="bg-white rounded-2xl shadow-xl p-6">
          <h2 className="text-lg font-semibold text-gray-800 mb-4">Captura de Imagen</h2>

          <input ref={fileRef} className="hidden" type="file" accept="image/*" onChange={onUpload}/>
          <div className="grid grid-cols-2 gap-3">
            <button onClick={()=>fileRef.current?.click()} className="bg-indigo-600 hover:bg-indigo-700 text-white font-semibold py-3 rounded-xl flex items-center justify-center gap-2"><Icon>{I.up}</Icon>Subir Foto</button>
            <button onClick={cameraActive?capturePhoto:startCamera} className="bg-purple-600 hover:bg-purple-700 text-white font-semibold py-3 rounded-xl flex items-center justify-center gap-2"><Icon>{I.cam}</Icon>{cameraActive?"Capturar":"Cámara"}</button>
          </div>

          {cameraActive && (
            <div className="mt-4">
              <div className="video-shell">
                <video ref={videoRef} playsInline autoPlay muted></video>
                {/* Guía y controles */}
                {useGuide && (
                  <>
                    <div className="mask z-20"></div>
                    <div className="guide-rect z-30" style={liveGuideStyle()}></div>
                  </>
                )}
              </div>
              {!videoReady && (
                <p className="text-xs text-gray-600 mt-2">
                  Si no ves la cámara en iOS, toca “Cámara” otra vez. Asegúrate de tener permisos y que la página esté en HTTPS.
                </p>
              )}

              <div className="mt-3 bg-gray-50 rounded-xl p-3 flex flex-col sm:flex-row gap-3 items-center">
                <label className="text-sm flex items-center gap-2">
                  <input type="checkbox" checked={useGuide} onChange={e=>{setUseGuide(e.target.checked); setGuideLock(false);}}/>
                  Usar Guía CR80
                </label>
                <div className="flex items-center gap-2 grow">
                  <span className="text-xs text-gray-600">Tamaño</span>
                  <input type="range" min="35" max="80" value={guideScale} onChange={e=>{setGuideScale(+e.target.value); setGuideLock(false);}} className="w-full"/>
                </div>
                <div className="flex items-center gap-2">
                  <span className={`text-xs font-semibold ${guideMatch>=.7?"text-green-700":"text-gray-700"}`}>Match {(guideMatch*100).toFixed(0)}%</span>
                  <button onClick={()=>setGuideLock(guideMatch>=.7)} className={`text-sm px-3 py-1 rounded-lg ${guideLock?"bg-green-600 text-white":"bg-emerald-100 text-emerald-700"}`}>{guideLock?"Bloqueado ✓":"Bloquear"}</button>
                </div>
              </div>

              <button onClick={stopCamera} className="w-full mt-2 bg-red-500 hover:bg-red-600 text-white py-2 rounded-lg text-sm">Cerrar Cámara</button>
            </div>
          )}

          {image && !cameraActive && (
            <button onClick={analyze} disabled={processing} className="w-full mt-4 bg-green-600 hover:bg-green-700 disabled:bg-gray-400 text-white font-semibold py-3 rounded-xl flex items-center justify-center gap-2">
              <Icon>{I.rule}</Icon>{processing?"Procesando…":"Analizar IPD"}
            </button>
          )}
        </div>

        {image && !cameraActive && (
          <div className="bg-white rounded-2xl shadow-xl p-6 mt-6">
            <h3 className="text-lg font-semibold text-gray-800 mb-3">Imagen</h3>
            <img src={image} alt="captura" className="w-full rounded-xl"/>
          </div>
        )}

        {annotated && (
          <div className="bg-white rounded-2xl shadow-xl p-6 mt-6">
            <div className="flex justify-between items-center mb-3">
              <h3 className="text-lg font-semibold text-gray-800">Imagen anotada</h3>
              <button onClick={downloadPNG} className="bg-blue-600 hover:bg-blue-700 text-white py-2 px-4 rounded-lg text-sm flex items-center gap-2"><Icon>{I.dl}</Icon>Descargar</button>
            </div>
            <img src={annotated} alt="anotada" className="w-full rounded-xl"/>
          </div>
        )}

        {results && (
          <div className="bg-gradient-to-br from-indigo-600 to-purple-600 text-white rounded-2xl shadow-xl p-6 mt-6">
            <div className="flex justify-between items-center mb-4">
              <h3 className="text-xl font-semibold">IPD</h3>
              <button onClick={downloadJSON} className="bg-white text-indigo-600 hover:bg-indigo-50 py-2 px-4 rounded-lg text-sm flex items-center gap-2"><Icon>{I.dl}</Icon>JSON</button>
            </div>
            <div className="bg-white/20 rounded-xl p-6 text-center">
              <p className="text-sm opacity-90 mb-2">Distancia interpupilar</p>
              <p className="text-5xl font-bold">{results.measurements.DI_mm}</p>
              <p className="text-2xl">mm</p>
              <p className="mt-3 text-sm opacity-90">Escala: {results.calibration.method}</p>
            </div>
          </div>
        )}

        {error && (
          <div className="bg-red-50 border-l-4 border-red-500 rounded-xl p-4 mt-6">
            <div className="flex items-center gap-2"><Icon>{I.warn}</Icon><b>Error</b></div>
            <p className="text-sm text-red-800 mt-2">{error}</p>
          </div>
        )}

        <canvas ref={canvasRef} className="hidden-canvas"></canvas>

        {!image && !cameraActive && (
          <div className="mt-6 bg-white rounded-2xl shadow-xl p-6">
            <div className="flex items-center gap-2 text-indigo-700 mb-2"><Icon>{I.info}</Icon><b>Cómo usar la Guía</b></div>
            <ol className="list-decimal ml-5 text-sm text-gray-700 space-y-1">
              <li>Enciende la cámara.</li>
              <li>Activa “Usar Guía CR80”, ajusta el tamaño y pon tu tarjeta dentro.</li>
              <li>Con <b>Match ≥ 70%</b> bloquea la guía y captura.</li>
              <li>Procesa la imagen. Si no bloqueas, se intentará detectar la tarjeta con OpenCV.</li>
            </ol>
          </div>
        )}

        <p className="text-center text-xs text-gray-500 my-6">© {new Date().getFullYear()} — CR80 Guide + OpenCV + MediaPipe</p>
      </div>
    </div>
  );
}

const root = ReactDOM.createRoot(document.getElementById('root'));
root.render(<App/>);
</script>
</body>
</html>