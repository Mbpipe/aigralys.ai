<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"/>
  <title>Medidor √ìptico Facial ‚Äî Gu√≠a CR80 + OpenCV/MediaPipe</title>

  <!-- Tailwind -->
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- React 18 UMD + Babel -->
  <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
  <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
  <script crossorigin src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

  <!-- OpenCV.js (opcional) -->
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>

  <style>
    html,body{background:#eef2ff}
    video.cam{width:100%;height:auto;max-height:62vh;background:#000;border-radius:.75rem;object-fit:cover;transform:scaleX(-1)}
    canvas.overlay{position:absolute;inset:0;pointer-events:none}
    .tag{font-variant-numeric:tabular-nums}
    .capture-fab{
      position:absolute;left:50%;top:50%;transform:translate(-50%,-50%);
      width:84px;height:84px;border-radius:9999px;display:flex;align-items:center;justify-content:center;
      background:rgba(37,99,235,.92);color:#fff;font-size:28px;border:3px solid #fff;box-shadow:0 10px 30px rgba(37,99,235,.35)
    }
  </style>
</head>
<body>
<div id="root"></div>

<script type="text/babel">
const {useRef,useState,useEffect,useMemo} = React;

const CR80_W=85.60, CR80_H=53.98, CR80_AR=CR80_W/CR80_H;

/* ---- util borde simple en ROI ---- */
function edgeScoreInROI(imgData,w,h){
  const t=3; let e=0, tot=0;
  for(let y=0;y<h;y++){
    const top=(y<t)||(y>=h-t);
    for(let x=0;x<w;x++){
      if(!top && (x>=t && x<w-t)) continue;
      const i=(y*w+x)*4;
      const lum=0.299*imgData.data[i]+0.587*imgData.data[i+1]+0.114*imgData.data[i+2];
      if(lum<75 || lum>205) e++; tot++;
    }
  }
  return tot? e/tot : 0;
}

function App(){
  const [state,setState]=useState('idle');   // idle|ready|error
  const [err,setErr]=useState('');
  const [ocvReady,setOcvReady]=useState(false);

  const videoRef=useRef(null);
  const streamRef=useRef(null);
  const overlayRef=useRef(null);

  const [cameraOn,setCameraOn]=useState(false);
  const [image,setImage]=useState(null);
  const [annotated,setAnnotated]=useState(null);
  const [log,setLog]=useState([]);

  // gu√≠a + autocaptura
  const [useGuide,setUseGuide]=useState(true);
  const [autoCapture,setAutoCapture]=useState(true);
  const [autoProcess,setAutoProcess]=useState(true);       // NUEVO
  const [scorePct,setScorePct]=useState(0);
  const [ocvPct,setOcvPct]=useState(0);
  const [autoThreshold,setAutoThreshold]=useState(0.70);
  const autoBusyRef=useRef(false);                         // debounce autocapture

  // escala por gu√≠a + ajuste fino
  const [guidePx,setGuidePx]=useState(130);
  const [fineAdj,setFineAdj]=useState(0);                  // -10..+10 %
  const pxPerMmGuide=useMemo(()=>{
    return (guidePx/CR80_W) * (1+fineAdj/100);
  },[guidePx,fineAdj]);

  // MediaPipe
  const [faceMesh,setFaceMesh]=useState(null);
  useEffect(()=>{
    const init=()=>{
      try{
        const fm=new window.FaceMesh({locateFile:f=>`https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`});
        fm.setOptions({maxNumFaces:1,refineLandmarks:true,minDetectionConfidence:0.5,minTrackingConfidence:0.5});
        setFaceMesh(fm);
      }catch(_){}
    };
    if(typeof window.FaceMesh==='undefined'){
      const s=document.createElement('script'); s.async=true;
      s.src='https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js';
      s.onload=()=>{
        const u=document.createElement('script'); u.async=true;
        u.src='https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js';
        u.onload=init; document.body.appendChild(u);
      };
      document.body.appendChild(s);
    }else init();
  },[]);

  // OpenCV listo?
  useEffect(()=>{
    const t=setInterval(()=>{ if(window.cv && window.cv.Mat){ setOcvReady(true); clearInterval(t);} },300);
    return()=>clearInterval(t);
  },[]);

  /* ---- c√°mara con reintentos ---- */
  const startCamera=()=>{
    setErr('');
    const go=async(retry=0)=>{
      const v=videoRef.current;
      if(!v){ if(retry<4) return requestAnimationFrame(()=>go(retry+1)); setErr('videoRef no disponible'); setState('error'); return; }
      try{
        v.setAttribute('playsinline',''); v.setAttribute('autoplay',''); v.muted=true; v.playsInline=true;
        const stream=await navigator.mediaDevices.getUserMedia({video:{facingMode:{ideal:'user'},width:{ideal:1280},height:{ideal:720}},audio:false});
        streamRef.current=stream; v.srcObject=stream; await v.play();
        setCameraOn(true); setState('ready');
      }catch(e){ setErr('No se pudo acceder a la c√°mara: '+(e.message||e)); setState('error');}
    };
    go();
  };
  const stopCamera=()=>{
    const v=videoRef.current; if(v){v.pause(); v.srcObject=null;}
    if(streamRef.current){ streamRef.current.getTracks().forEach(t=>t.stop()); streamRef.current=null; }
    setCameraOn(false);
  };

  /* ---- overlay y autocaptura ---- */
  useEffect(()=>{
    if(!cameraOn || !useGuide) return;
    const v=videoRef.current, c=overlayRef.current; if(!v||!c) return;
    const ctx=c.getContext('2d',{willReadFrequently:true});
    let raf=0, frame=0;

    const loop=()=>{
      if(!v.videoWidth){ raf=requestAnimationFrame(loop); return; }
      c.width=v.videoWidth; c.height=v.videoHeight;

      ctx.save(); ctx.scale(-1,1); ctx.drawImage(v,-c.width,0,c.width,c.height); ctx.restore();

      // ROI bajo la nariz
      const gw=guidePx, gh=Math.round(guidePx/CR80_AR);
      const gx=Math.round((c.width-gw)/2);
      const gy=Math.round(c.height*0.58 - gh/2);

      // m√°scara
      ctx.fillStyle='rgba(0,0,0,.38)'; ctx.fillRect(0,0,c.width,c.height);
      ctx.clearRect(gx,gy,gw,gh);

      // score bordes
      const img=ctx.getImageData(gx,gy,gw,gh);
      const eScore=edgeScoreInROI(img,gw,gh);
      let combined=eScore, ocvScore=0;

      // OpenCV (cada 3 frames)
      if(ocvReady && frame%3===0){
        try{
          const cv=window.cv;
          const src=cv.matFromImageData(img);
          const gray=new cv.Mat(), bl=new cv.Mat(), ed=new cv.Mat();
          cv.cvtColor(src,gray,cv.COLOR_RGBA2GRAY);
          cv.GaussianBlur(gray,bl,new cv.Size(5,5),0);
          let sum=0; const d=bl.data; for(let i=0;i<d.length;i++) sum+=d[i];
          const mean=sum/d.length; const lo=Math.max(0,.66*mean), hi=Math.min(255,1.33*mean);
          cv.Canny(bl,ed,lo,hi);
          const contours=new cv.MatVector(), hier=new cv.Mat();
          cv.findContours(ed,contours,hier,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE);
          let best=0;
          for(let i=0;i<contours.size();i++){
            const cnt=contours.get(i); const area=cv.contourArea(cnt);
            if(area<(gw*gh)*0.05){ cnt.delete(); continue; }
            const rect=cv.minAreaRect(cnt);
            const long=Math.max(rect.size.width,rect.size.height), short=Math.min(rect.size.width,rect.size.height);
            const ar=long/short;
            const asp=Math.max(0,1-Math.min(Math.abs(ar-CR80_AR)/0.35,1));
            const cont=Math.max(0,Math.min(1,(area/(gw*gh))*2.2));
            best=Math.max(best, asp*0.7+cont*0.3); cnt.delete();
          }
          gray.delete(); bl.delete(); ed.delete(); contours.delete(); hier.delete(); src.delete();
          ocvScore=best; combined=Math.max(combined,ocvScore);
        }catch(_){}
      }
      setScorePct(combined); setOcvPct(ocvScore);

      // borde
      ctx.lineWidth=4; ctx.strokeStyle=combined>=autoThreshold? '#22c55e':'#a78bfa'; ctx.strokeRect(gx,gy,gw,gh);
      ctx.font='700 22px system-ui,-apple-system,Segoe UI'; ctx.fillStyle='#fff'; ctx.strokeStyle='#000'; ctx.lineWidth=4;
      const label=`Gu√≠a CR80 ‚Äî ajusta ‚Ä¢ score ${Math.round(combined*100)}%`;
      ctx.strokeText(label,14,Math.max(26,gy-12)); ctx.fillText(label,14,Math.max(26,gy-12));

      // autocaptura con debounce 1200ms
      if(autoCapture && combined>=autoThreshold && !autoBusyRef.current){
        autoBusyRef.current=true;
        captureAndMaybeProcess(true);
        setTimeout(()=>{ autoBusyRef.current=false; },1200);
      }

      frame++; raf=requestAnimationFrame(loop);
    };
    raf=requestAnimationFrame(loop);
    return()=>cancelAnimationFrame(raf);
  },[cameraOn,useGuide,guidePx,autoCapture,autoThreshold,ocvReady,autoProcess,pxPerMmGuide]);

  /* ---- captura + procesamiento autom√°tico ---- */
  const captureAndMaybeProcess=(fromAuto=false)=>{
    const v=videoRef.current; if(!v||!v.videoWidth){ setErr('La c√°mara no est√° lista.'); return; }
    const c=document.createElement('canvas'); c.width=v.videoWidth; c.height=v.videoHeight;
    const x=c.getContext('2d'); x.drawImage(v,0,0,c.width,c.height);
    const dataUrl=c.toDataURL('image/jpeg',0.92);
    setImage(dataUrl); setAnnotated(null);
    if(fromAuto) pushLog('Auto-captura (score OK)');
    if(autoProcess) process(dataUrl);              // <<< procesar ya mismo
  };

  /* ---- procesar (acepta dataUrl opcional) ---- */
  const process=async(dataUrl=null)=>{
    const src = dataUrl || image;
    if(!src){ setErr('No hay imagen para procesar.'); return; }
    setErr(''); pushLog('Procesando‚Ä¶');
    try{
      const img=await new Promise((res,rej)=>{ const m=new Image(); m.src=src; m.onload=()=>res(m); m.onerror=rej; });
      const pxPerMm = pxPerMmGuide;

      // landmarks
      const getLm=()=> new Promise((resolve)=>{
        if(faceMesh){
          const c=document.createElement('canvas'); c.width=img.width; c.height=img.height;
          c.getContext('2d').drawImage(img,0,0);
          faceMesh.onResults(r=>{
            if(r.multiFaceLandmarks && r.multiFaceLandmarks[0]){
              const L=r.multiFaceLandmarks[0];
              const iris=(a)=>({x:a.reduce((s,l)=>s+l.x*img.width,0)/a.length, y:a.reduce((s,l)=>s+l.y*img.height,0)/a.length});
              resolve({right:iris(L.slice(468,472)), left:iris(L.slice(473,477)), method:'MediaPipe'});
            }else{
              const cx=img.width/2, cy=img.height*0.45, d=img.width*0.15;
              resolve({right:{x:cx+d/2,y:cy}, left:{x:cx-d/2,y:cy}, method:'Estimaci√≥n'});
            }
          });
          faceMesh.send({image:c});
        }else{
          const cx=img.width/2, cy=img.height*0.45, d=img.width*0.15;
          resolve({right:{x:cx+d/2,y:cy}, left:{x:cx-d/2,y:cy}, method:'Estimaci√≥n'});
        }
      });
      const lm=await getLm();

      const dx=lm.right.x-lm.left.x, dy=lm.right.y-lm.left.y;
      const ipd = Math.hypot(dx,dy)/pxPerMm;
      const ipdRounded = Math.round(ipd*10)/10;

      // anotada
      const out=document.createElement('canvas'); out.width=img.width; out.height=img.height;
      const a=out.getContext('2d'); a.drawImage(img,0,0);
      a.fillStyle='#ef4444';
      a.beginPath(); a.arc(lm.left.x,lm.left.y,12,0,Math.PI*2); a.fill();
      a.beginPath(); a.arc(lm.right.x,lm.right.y,12,0,Math.PI*2); a.fill();
      a.strokeStyle='#ef4444'; a.lineWidth=4; a.beginPath(); a.moveTo(lm.left.x,lm.left.y); a.lineTo(lm.right.x,lm.right.y); a.stroke();
      a.font='700 28px system-ui,-apple-system'; a.fillStyle='#fff'; a.strokeStyle='#000'; a.lineWidth=6;
      const mx=(lm.left.x+lm.right.x)/2, my=(lm.left.y+lm.right.y)/2-24;
      a.strokeText(`IPD: ${ipdRounded} mm`,mx-90,my); a.fillText(`IPD: ${ipdRounded} mm`,mx-90,my);
      setAnnotated(out.toDataURL('image/png'));

      pushLog(`IPD: ${ipdRounded} mm ‚Ä¢ escala ${pxPerMm.toFixed(3)} px/mm`);
    }catch(e){
      setErr('No se pudo procesar: '+(e.message||e));
    }
  };

  const pushLog=(m)=> setLog(L=>[`${new Date().toTimeString().slice(0,8)}  ${m}`,...L].slice(0,30));

  return (
    <div className="min-h-screen p-4">
      <div className="max-w-3xl mx-auto space-y-4">
        <header className="bg-white rounded-2xl shadow p-5 border-t-4 border-indigo-500">
          <div className="flex items-center justify-between gap-3">
            <div>
              <h1 className="text-3xl font-bold">Medidor √ìptico Facial</h1>
              <p className="text-slate-600">Gu√≠a CR80 + OpenCV/MediaPipe (auto-proceso)</p>
            </div>
            <div className="flex gap-2 text-xs">
              <span className="px-2 py-1 rounded bg-slate-100">secure: <b className="tag">{location.protocol==='https:'?'true':'false'}</b></span>
              <span className="px-2 py-1 rounded bg-slate-100">opencv: <b className="tag">{ocvReady?'ready':'loading'}</b></span>
              <span className="px-2 py-1 rounded bg-slate-100">estado: <b className="tag">{state}</b></span>
            </div>
          </div>
        </header>

        <section className="bg-white rounded-2xl shadow p-5">
          <h2 className="text-xl font-semibold mb-3">Captura de Imagen</h2>

          <div className="grid grid-cols-3 gap-3 mb-3">
            <label className="flex items-center justify-center gap-2 bg-slate-800 text-white rounded-xl py-3 cursor-pointer">
              üñºÔ∏è <span>Subir Foto</span>
              <input type="file" accept="image/*" className="hidden"
                     onChange={e=>{
                       const f=e.target.files?.[0]; if(!f) return;
                       const rd=new FileReader(); rd.onload=ev=>{ setImage(ev.target.result); setAnnotated(null); if(autoProcess) process(ev.target.result); };
                       rd.readAsDataURL(f);
                     }}/>
            </label>
            <button onClick={startCamera} className="bg-violet-600 hover:bg-violet-700 text-white rounded-xl py-3">üì∑ C√°mara</button>
            <button onClick={stopCamera} className="bg-rose-600 hover:bg-rose-700 text-white rounded-xl py-3">üî¥ Cerrar</button>
          </div>

          {err && <div className="bg-red-50 text-red-800 border border-red-200 rounded-xl p-3 mb-3">{err}</div>}

          <div className="relative">
            <video ref={videoRef} className="cam" autoplay playsinline muted></video>
            {cameraOn && useGuide && <canvas ref={overlayRef} className="overlay"></canvas>}
            {cameraOn && <button className="capture-fab" aria-label="Capturar" onClick={()=>captureAndMaybeProcess(false)}>üì∏</button>}
          </div>

          <div className="mt-3 flex flex-wrap items-center gap-3">
            <label className="inline-flex items-center gap-2">
              <input type="checkbox" className="scale-110" checked={useGuide} onChange={e=>setUseGuide(e.target.checked)}/>
              <span>Usar Gu√≠a CR80</span>
            </label>
            <label className="inline-flex items-center gap-2">
              <input type="checkbox" className="scale-110" checked={autoCapture} onChange={e=>setAutoCapture(e.target.checked)}/>
              <span>Auto-capturar (‚â•{Math.round(autoThreshold*100)}%)</span>
            </label>
            <label className="inline-flex items-center gap-2">
              <input type="checkbox" className="scale-110" checked={autoProcess} onChange={e=>setAutoProcess(e.target.checked)}/>
              <span>Procesar al capturar</span>
            </label>
            <div className="ml-auto text-sm text-slate-600">score: <b className="tag">{Math.round(scorePct*100)}%</b> ¬∑ OpenCV: <b className="tag">{Math.round(ocvPct*100)}%</b></div>
          </div>

          <div className="mt-3">
            <div className="text-sm text-slate-700 mb-1">Ajuste fino escala (¬±10%) ¬∑ actual: <b className="tag">{fineAdj}%</b></div>
            <input type="range" min="-10" max="10" step="1" value={fineAdj} onChange={e=>setFineAdj(parseInt(e.target.value))} className="w-full"/>
          </div>
        </section>

        {image && !autoProcess && (
          <section className="bg-white rounded-2xl shadow p-5">
            <h3 className="font-semibold mb-3">Imagen capturada</h3>
            <img src={image} className="w-full rounded-lg shadow" alt="captura"/>
            <div className="flex items-center gap-3 mt-4">
              <button onClick={()=>process()} className="bg-blue-600 hover:bg-blue-700 text-white rounded-xl py-2 px-4">Procesar</button>
              <div className="text-sm text-slate-600">Escala: <b className="tag">{pxPerMmGuide.toFixed(3)}</b> px/mm</div>
            </div>
          </section>
        )}

        {annotated && (
          <section className="bg-white rounded-2xl shadow p-5">
            <h3 className="font-semibold mb-3">Resultado</h3>
            <img src={annotated} className="w-full rounded-lg shadow" alt="anotada"/>
            <a className="inline-block mt-3 px-3 py-2 rounded bg-indigo-600 text-white" download="resultado.png" href={annotated}>Descargar PNG</a>
          </section>
        )}

        <section className="bg-white rounded-2xl shadow p-5">
          <h3 className="font-semibold mb-2">Log</h3>
          <pre className="bg-slate-900 text-slate-100 p-3 rounded-lg text-xs overflow-auto max-h-60">{(log.join('\n'))||'‚Äî'}</pre>
        </section>

        <footer className="text-center text-xs text-slate-500 py-6">¬© 2025 ‚Äî CR80 + OpenCV + MediaPipe</footer>
      </div>
    </div>
  );
}

const root = ReactDOM.createRoot(document.getElementById('root'));
root.render(<App/>);
</script>
</body>
</html>