<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"/>
  <title>Medidor √ìptico Facial ‚Äî CR80 + OpenCV/MediaPipe</title>

  <!-- Tailwind -->
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- React 18 UMD + Babel -->
  <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
  <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
  <script crossorigin src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

  <!-- OpenCV (opcional) -->
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>

  <style>
    html,body{background:#eef2ff}
    video.cam{
      width:100%; height:auto; max-height:62vh; background:#000;
      border-radius:.8rem; object-fit:cover; transform:scaleX(-1);
    }
    canvas.overlay{ position:absolute; left:0; top:0; width:100%; height:100%; pointer-events:none; }
    .tag{font-variant-numeric:tabular-nums}
    .btn-fab{
      position:absolute; left:50%; transform:translateX(-50%);
      bottom:12px; width:64px; height:64px; border-radius:9999px;
      display:flex; align-items:center; justify-content:center;
      background:#0ea5e9; color:#fff; box-shadow:0 10px 26px rgba(2,132,199,.35);
      border:4px solid rgba(255,255,255,.85);
    }
    .btn-fab:active{transform:translateX(-50%) scale(.96)}
  </style>
</head>
<body>
<div id="root"></div>

<script type="text/babel">
const {useState,useEffect,useRef,useMemo} = React;

const CR80_W=85.60, CR80_H=53.98, CR80_AR=CR80_W/CR80_H;

/* ---------- helpers ---------- */
const secure = location.protocol==='https:' || location.hostname==='localhost';
const sleep = (ms)=> new Promise(r=>setTimeout(r,ms));

/* ---------- App ---------- */
function App(){
  const [faceReady,setFaceReady]=useState(false);
  const [status,setStatus]=useState('idle');
  const [msg,setMsg]=useState('');
  const [opencvReady,setOpenCvReady]=useState(false);

  const [image,setImage]=useState(null);
  const [annotated,setAnnotated]=useState(null);
  const [result,setResult]=useState(null);
  const [err,setErr]=useState('');

  const videoRef=useRef(null);
  const overlayRef=useRef(null);
  const streamRef=useRef(null);

  // gu√≠a
  const [useGuide,setUseGuide]=useState(true);
  const [autoCapture,setAutoCapture]=useState(true);
  const [guidePx,setGuidePx]=useState(220);      // ancho gu√≠a (px)
  const [edgePct,setEdgePct]=useState(0);
  const [ocvPct,setOcvPct]=useState(0);
  const [streak,setStreak]=useState(0);

  // ¬±10% ajuste fino
  const [finePct,setFinePct]=useState(0);        // -10 .. +10
  const fineFactor = useMemo(()=> 1 + (finePct/100), [finePct]);

  // escala final desde gu√≠a
  const pxPerMmFromGuide = useMemo(()=> guidePx/CR80_W, [guidePx]);
  const fusedScale = useMemo(()=> pxPerMmFromGuide * fineFactor, [pxPerMmFromGuide,fineFactor]);

  /* ---- OpenCV listo? ---- */
  useEffect(()=>{
    const id=setInterval(()=>{
      if(window.cv && window.cv.Mat){ setOpenCvReady(true); clearInterval(id); }
    }, 300);
    return ()=> clearInterval(id);
  },[]);

  /* ---- MediaPipe FaceMesh ---- */
  useEffect(()=>{
    const init=()=>{
      try{
        const fm=new window.FaceMesh({
          locateFile:f=>`https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`
        });
        fm.setOptions({maxNumFaces:1,refineLandmarks:true,minDetectionConfidence:0.5,minTrackingConfidence:0.5});
        window.__faceMesh=fm; setFaceReady(true);
      }catch(_){ setFaceReady(false); }
    };
    if(typeof window.FaceMesh==='undefined'){
      const s=document.createElement('script');
      s.src='https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js';
      s.async=true;
      s.onload=()=>{
        const u=document.createElement('script');
        u.src='https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js';
        u.async=true; u.onload=init; u.onerror=()=>setFaceReady(false);
        document.body.appendChild(u);
      };
      s.onerror=()=>setFaceReady(false);
      document.body.appendChild(s);
    }else init();
  },[]);

  /* ---------- C√°mara ---------- */
  const startCam = async ()=>{
    setErr(''); setResult(null); setAnnotated(null); setImage(null);
    try{
      if(!secure) throw new Error('Se requiere HTTPS para usar la c√°mara.');
      const v=videoRef.current;
      v.setAttribute('playsinline',''); v.playsInline=true; v.muted=true;
      const stream = await navigator.mediaDevices.getUserMedia({
        video:{ facingMode:{ideal:'user'}, width:{ideal:1280}, height:{ideal:720} },
        audio:false
      });
      streamRef.current=stream;
      v.srcObject=stream;
      await v.play().catch(()=>{});
      setStatus('ready');
    }catch(e){
      setErr('No se pudo acceder a la c√°mara: '+e.message);
      setStatus('error');
    }
  };
  const stopCam = ()=>{
    const v=videoRef.current;
    if(v){ v.pause(); v.srcObject=null; }
    if(streamRef.current){ streamRef.current.getTracks().forEach(t=>t.stop()); }
    streamRef.current=null;
    setStatus('stopped');
  };

  /* ---------- OpenCV: detecci√≥n en ROI ---------- */
  function ocvDetect(imgData,w,h){
    const cv=window.cv; if(!cv||!cv.Mat) return null;
    try{
      const src=cv.matFromImageData(imgData);
      const gray=new cv.Mat(), blur=new cv.Mat(), edges=new cv.Mat();
      cv.cvtColor(src,gray,cv.COLOR_RGBA2GRAY);
      cv.GaussianBlur(gray,blur,new cv.Size(5,5),0);
      let sum=0; const d=blur.data; for(let i=0;i<d.length;i++) sum+=d[i];
      const mean=sum/d.length; const lo=Math.max(0,0.66*mean), hi=Math.min(255,1.33*mean);
      cv.Canny(blur,edges,lo,hi);

      const contours=new cv.MatVector(), hier=new cv.Mat();
      cv.findContours(edges,contours,hier,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE);
      let best=0;
      for(let i=0;i<contours.size();i++){
        const cnt=contours.get(i);
        const area=cv.contourArea(cnt);
        if(area<(w*h)*0.15){ cnt.delete(); continue; } // exige ocupar ROI
        const peri=cv.arcLength(cnt,true);
        const approx=new cv.Mat(); cv.approxPolyDP(cnt,approx,0.02*peri,true);
        if(approx.rows===4){
          const rect=cv.minAreaRect(cnt);
          const W=rect.size.width, H=rect.size.height;
          const ar=(Math.max(W,H)/Math.min(W,H));
          const aspectScore = 1 - Math.min(Math.abs(ar - (CR80_AR))/0.25, 1);
          const fillScore = Math.min(1, (area/(w*h))*2);  // llena el rect
          const score = Math.max(0, (aspectScore*0.7 + fillScore*0.3));
          if(score>best) best=score;
        }
        approx.delete(); cnt.delete();
      }
      gray.delete(); blur.delete(); edges.delete(); contours.delete(); hier.delete(); src.delete();
      return best; // 0..1
    }catch(_){ return null; }
  }

  /* ---------- Overlay loop (gu√≠a + score) ---------- */
  useEffect(()=>{
    if(status!=='ready' || !useGuide) return;
    const v=videoRef.current, c=overlayRef.current, ctx=c.getContext('2d',{willReadFrequently:true});
    let raf=0, frame=0, streakLoc=0;

    const loop=()=>{
      if(!v.videoWidth){ raf=requestAnimationFrame(loop); return; }
      c.width=v.videoWidth; c.height=v.videoHeight;

      // espejo para que todo ‚Äúcoincida‚Äù visualmente
      ctx.save(); ctx.scale(-1,1); ctx.drawImage(v,-c.width,0,c.width,c.height); ctx.restore();

      const gw=guidePx, gh=Math.round(guidePx/CR80_AR);
      const gx=Math.round((c.width-gw)/2), gy=Math.round(c.height*0.52 - gh/2); // debajo de nariz

      // medir bordes luminosidad en per√≠metro
      const roi=ctx.getImageData(gx,gy,gw,gh);
      const thick=3; let edge=0, tot=0;
      for(let y=0;y<gh;y++){
        for(let x=0;x<gw;x++){
          const per = (y<thick)||(y>=gh-thick)||(x<thick)||(x>=gw-thick);
          if(!per) continue;
          const i=(y*gw+x)*4;
          const lum=0.299*roi.data[i]+0.587*roi.data[i+1]+0.114*roi.data[i+2];
          if(lum<70 || lum>210) edge++;
          tot++;
        }
      }
      const edgeScore = tot? edge/tot : 0;
      setEdgePct(edgeScore);

      // openCV score cada 3 frames (si est√° disponible)
      let ocvScore = ocvPct;
      if(opencvReady && frame%3===0){
        const s = ocvDetect(roi, gw, gh);
        if(s!==null){ ocvScore=s; setOcvPct(s); }
      }
      frame++;

      // pintar overlay
      ctx.fillStyle='rgba(0,0,0,.32)'; ctx.fillRect(0,0,c.width,c.height);
      ctx.clearRect(gx,gy,gw,gh);
      const score = Math.max(edgeScore, ocvScore);
      const ok = score>=0.70;
      ctx.strokeStyle = ok? '#22c55e' : '#a78bfa';
      ctx.lineWidth=4; ctx.strokeRect(gx,gy,gw,gh);
      ctx.font='bold 24px system-ui, -apple-system';
      ctx.fillStyle='#fff';
      ctx.fillText(`Gu√≠a CR80 ‚Äî ${ok?'ajusta':'match'} ‚Ä¢ score ${Math.round(score*100)}%`, 20, 36);

      // autocaptura con racha de frames estables
      if(autoCapture){
        if(ok){ streakLoc++; } else { streakLoc=0; }
        setStreak(streakLoc);
        if(streakLoc>=6){ // ~6 frames ‚âà 100 ms
          capturePhoto(); streakLoc=0;
        }
      }

      raf=requestAnimationFrame(loop);
    };
    raf=requestAnimationFrame(loop);
    return ()=> cancelAnimationFrame(raf);
  },[status,useGuide,guidePx,autoCapture,opencvReady]);

  /* ---------- Captura & Procesado ---------- */
  const capturePhoto = ()=>{
    try{
      const v=videoRef.current; if(!v || !v.videoWidth){ setErr('La c√°mara a√∫n no est√° lista.'); return; }
      const c=document.createElement('canvas'); c.width=v.videoWidth; c.height=v.videoHeight;
      const x=c.getContext('2d'); x.drawImage(v,0,0,c.width,c.height); // sin espejo
      const url=c.toDataURL('image/jpeg',0.92);
      setImage(url); setResult(null); setAnnotated(null);
      // detener c√°mara para que ‚ÄúProcesar‚Äù no compita
      stopCam();
      setMsg('Foto capturada');
    }catch(e){ setErr('No se pudo capturar: '+e.message); }
  };

  const process = async ()=>{
    if(!image){ setErr('No hay imagen para procesar.'); return; }
    setErr(''); setMsg('Procesando‚Ä¶');

    try{
      const img = await new Promise((res,rej)=>{ const im=new Image(); im.src=image; im.onload=()=>res(im); im.onerror=rej; });

      // Landmarks (MediaPipe si est√°, si no: estimaci√≥n)
      const getLandmarks=()=> new Promise((resolve)=>{
        if(window.__faceMesh){
          const c=document.createElement('canvas'); c.width=img.width; c.height=img.height;
          c.getContext('2d').drawImage(img,0,0);
          window.__faceMesh.onResults(r=>{
            if(r.multiFaceLandmarks && r.multiFaceLandmarks[0]){
              const L=r.multiFaceLandmarks[0];
              const iris=(a)=>({x:a.reduce((s,l)=>s+l.x*img.width,0)/a.length, y:a.reduce((s,l)=>s+l.y*img.height,0)/a.length});
              resolve({ rightPupil:iris(L.slice(468,472)), leftPupil:iris(L.slice(473,477)), method:'MediaPipe', conf:0.95 });
            }else{
              const cx=img.width/2, cy=img.height*0.45, d=img.width*0.15;
              resolve({ rightPupil:{x:cx+d/2,y:cy}, leftPupil:{x:cx-d/2,y:cy}, method:'Estimaci√≥n', conf:0.65 });
            }
          });
          window.__faceMesh.send({image:c});
        }else{
          const cx=img.width/2, cy=img.height*0.45, d=img.width*0.15;
          resolve({ rightPupil:{x:cx+d/2,y:cy}, leftPupil:{x:cx-d/2,y:cy}, method:'Estimaci√≥n', conf:0.65 });
        }
      });

      const lm = await getLandmarks();

      // IPD con escala fusionada + ajuste fino
      const dx=lm.rightPupil.x-lm.leftPupil.x, dy=lm.rightPupil.y-lm.leftPupil.y;
      const ipd_mm = Math.round((Math.hypot(dx,dy)/fusedScale)*10)/10;

      // Imagen anotada
      const out=document.createElement('canvas'); out.width=img.width; out.height=img.height;
      const a=out.getContext('2d'); a.drawImage(img,0,0);
      a.fillStyle='#f00';
      a.beginPath(); a.arc(lm.leftPupil.x,lm.leftPupil.y,10,0,Math.PI*2); a.fill();
      a.beginPath(); a.arc(lm.rightPupil.x,lm.rightPupil.y,10,0,Math.PI*2); a.fill();
      a.strokeStyle='#f00'; a.lineWidth=3; a.beginPath();
      a.moveTo(lm.leftPupil.x,lm.leftPupil.y); a.lineTo(lm.rightPupil.x,lm.rightPupil.y); a.stroke();
      a.font='bold 22px system-ui,-apple-system'; a.fillStyle='#fff'; a.strokeStyle='#000'; a.lineWidth=5;
      const mx=(lm.leftPupil.x+lm.rightPupil.x)/2, my=(lm.leftPupil.y+lm.rightPupil.y)/2-22;
      a.strokeText(`IPD: ${ipd_mm} mm`, mx-70,my); a.fillText(`IPD: ${ipd_mm} mm`, mx-70,my);
      const annotatedUrl=out.toDataURL('image/png');

      setResult({
        ipd_mm, scale_px_per_mm: fusedScale, method: lm.method, confidence: lm.conf,
        notes: `Escala = gu√≠a (${(pxPerMmFromGuide).toFixed(3)}) √ó ajuste (${(fineFactor).toFixed(3)})`
      });
      setAnnotated(annotatedUrl);
      setMsg('Procesado listo');
    }catch(e){
      setErr('No se pudo procesar: '+(e.message||e));
    }
  };

  /* ---------- UI ---------- */
  return (
    <div className="min-h-screen p-4">
      <div className="max-w-3xl mx-auto space-y-4">
        <div className="bg-white rounded-2xl shadow p-5 border-t-4 border-indigo-500">
          <div className="flex items-center justify-between flex-wrap gap-3">
            <div>
              <h1 className="text-3xl font-bold">Medidor √ìptico Facial</h1>
              <p className="text-slate-600">Gu√≠a CR80 + OpenCV/MediaPipe (fusi√≥n escala + ajuste fino)</p>
            </div>
            <div className="flex gap-2 text-xs">
              <span className="px-2 py-1 rounded bg-slate-100">secure: {String(secure)}</span>
              <span className="px-2 py-1 rounded bg-slate-100">opencv: {opencvReady?'ready':'loading'}</span>
              <span className="px-2 py-1 rounded bg-slate-100">estado: {status}</span>
            </div>
          </div>
        </div>

        <div className="bg-white rounded-2xl shadow p-5">
          <h2 className="text-xl font-semibold mb-3">Captura de Imagen</h2>

          <div className="flex gap-3">
            <label className="inline-flex items-center justify-center gap-2 bg-slate-700 hover:bg-slate-800 text-white font-semibold py-2 px-4 rounded-xl cursor-pointer">
              üñºÔ∏è Subir Foto
              <input type="file" className="hidden" accept="image/*" onChange={(e)=>{
                const f=e.target.files?.[0]; if(!f) return;
                const rd=new FileReader(); rd.onload=ev=>{ setImage(ev.target.result); setAnnotated(null); setResult(null); stopCam(); }; rd.readAsDataURL(f);
              }}/>
            </label>
            <button onClick={startCam} className="bg-violet-600 hover:bg-violet-700 text-white font-semibold py-2 px-4 rounded-xl">üì∑ C√°mara</button>
            <button onClick={stopCam} className="bg-rose-600 hover:bg-rose-700 text-white font-semibold py-2 px-4 rounded-xl">üî¥ Cerrar</button>
          </div>

          {(status==='ready') && (
            <div className="mt-4 relative">
              <video ref={videoRef} className="cam" autoplay playsinline muted></video>
              {useGuide && <canvas ref={overlayRef} className="overlay"></canvas>}
              {/* FAB captura ‚Äì ahora NO tapa el rect√°ngulo (queda abajo) */}
              <button className="btn-fab" onClick={capturePhoto} title="Capturar">
                üì∏
              </button>

              <div className="absolute left-3 right-3 bottom-3 bg-black/55 text-white rounded-xl px-3 py-2 text-xs flex flex-wrap items-center gap-3">
                <div className="flex items-center gap-2">
                  <input type="checkbox" className="scale-110" checked={useGuide} onChange={e=>setUseGuide(e.target.checked)}/>
                  <span>Usar Gu√≠a</span>
                </div>
                <div className="flex items-center gap-2">
                  <input type="checkbox" className="scale-110" checked={autoCapture} onChange={e=>setAutoCapture(e.target.checked)}/>
                  <span>Auto-capturar</span>
                </div>
                <span className="ml-auto opacity-90">Ancho:{' '}
                  <b className="tag">{guidePx}px</b> ‚Ä¢ Alto:{' '}
                  <b className="tag">{Math.round(guidePx/CR80_AR)}px</b> ‚Ä¢ OpenCV:{' '}
                  <b className="tag">{Math.round(ocvPct*100)}%</b> ‚Ä¢ racha:{streak}
                </span>
              </div>
            </div>
          )}

          {/* tama√±o gu√≠a */}
          {status==='ready' && (
            <div className="mt-3">
              <input type="range" min="120" max="360" value={guidePx} onChange={e=>setGuidePx(parseInt(e.target.value))} className="w-full"/>
            </div>
          )}
        </div>

        {image && (
          <div className="bg-white rounded-2xl shadow p-5 space-y-4">
            <img src={image} alt="captura" className="w-full rounded-lg shadow"/>
            <div>
              <label className="text-sm font-medium text-slate-700">Ajuste fino escala</label>
              <div className="flex items-center gap-3 mt-1">
                <span className="text-xs w-10 text-right">-10%</span>
                <input type="range" min="-10" max="10" step="0.5" value={finePct}
                       onChange={e=>setFinePct(parseFloat(e.target.value))} className="flex-1"/>
                <span className="text-xs w-10">{Math.abs(finePct)}%</span>
              </div>
              <p className="text-xs text-slate-600 mt-1">
                Escala base: <b className="tag">{pxPerMmFromGuide.toFixed(3)}</b> px/mm ‚Ä¢ Ajuste: <b>{finePct}%</b> ‚Ä¢
                Escala resultante: <b className="tag">{fusedScale.toFixed(3)}</b> px/mm
              </p>
            </div>

            <button onClick={process} className="inline-flex items-center justify-center gap-2 bg-emerald-600 hover:bg-emerald-700 text-white font-semibold px-4 py-2 rounded-xl">
              üßÆ Procesar
            </button>
          </div>
        )}

        {result && (
          <div className="bg-white rounded-2xl shadow p-5 space-y-3">
            <h3 className="font-semibold text-lg">Resultado</h3>
            <div className="grid grid-cols-2 gap-3">
              <div className="p-3 rounded bg-indigo-50">
                <div className="text-xs text-slate-600">IPD</div>
                <div className="text-2xl font-bold">{result.ipd_mm} mm</div>
              </div>
              <div className="p-3 rounded bg-violet-50">
                <div className="text-xs text-slate-600">Escala</div>
                <div className="text-xl font-semibold tag">{result.scale_px_per_mm.toFixed(3)} px/mm</div>
                <div className="text-xs text-slate-500">{result.notes}</div>
              </div>
            </div>
            {annotated && (
              <div className="mt-2">
                <img src={annotated} className="w-full rounded-lg shadow" alt="anotada"/>
                <a download={`annotated-${Date.now()}.png`} href={annotated}
                   className="inline-block mt-3 px-3 py-2 rounded bg-blue-600 text-white">Descargar PNG</a>
              </div>
            )}
          </div>
        )}

        {(msg || err) && (
          <div className={`${err?'bg-red-50 text-red-800 border-red-200':'bg-emerald-50 text-emerald-800 border-emerald-200'} border rounded-xl p-3`}>
            {err||msg}
          </div>
        )}

        <div className="text-center text-xs text-slate-500 py-4">¬© 2025 ‚Äî CR80 + OpenCV + MediaPipe</div>
      </div>
    </div>
  );
}

const root = ReactDOM.createRoot(document.getElementById('root'));
root.render(<App/>);
</script>
</body>
</html>